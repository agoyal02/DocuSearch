#!/usr/bin/env python3
"""
Test script for LLM UI configuration
"""

import requests
import json

# Test configuration
BASE_URL = "http://localhost:5000"

def test_llm_status():
    """Test LLM status endpoint"""
    print("ğŸ§ª Testing LLM Status...")
    
    try:
        response = requests.get(f"{BASE_URL}/llm_status")
        if response.status_code == 200:
            status = response.json()
            print("âœ… LLM Status endpoint working")
            print(f"   Enabled: {status['enabled']}")
            print(f"   Available: {status['available']}")
            print(f"   Provider: {status['provider']}")
            print(f"   Model: {status['model']}")
        else:
            print(f"âŒ LLM Status endpoint failed: {response.status_code}")
    except Exception as e:
        print(f"âŒ LLM Status endpoint error: {e}")

def test_llm_config_save():
    """Test LLM configuration save"""
    print("\nğŸ§ª Testing LLM Configuration Save...")
    
    try:
        config_data = {
            "provider": "openai",
            "api_key": "test-key-123",
            "model": "gpt-3.5-turbo",
            "base_url": ""
        }
        
        response = requests.post(f"{BASE_URL}/save_llm_config", json=config_data)
        if response.status_code == 200:
            result = response.json()
            print("âœ… LLM Configuration save working")
            print(f"   Success: {result['success']}")
            print(f"   Message: {result['message']}")
        else:
            print(f"âŒ LLM Configuration save failed: {response.status_code}")
    except Exception as e:
        print(f"âŒ LLM Configuration save error: {e}")

def test_llm_connection():
    """Test LLM connection test"""
    print("\nğŸ§ª Testing LLM Connection Test...")
    
    try:
        test_data = {
            "provider": "openai",
            "api_key": "test-key-123",
            "model": "gpt-3.5-turbo",
            "base_url": ""
        }
        
        response = requests.post(f"{BASE_URL}/test_llm", json=test_data)
        if response.status_code == 200:
            result = response.json()
            print("âœ… LLM Connection test working")
            print(f"   Success: {result['success']}")
            if result['success']:
                print(f"   Message: {result['message']}")
            else:
                print(f"   Error: {result['error']}")
        else:
            print(f"âŒ LLM Connection test failed: {response.status_code}")
    except Exception as e:
        print(f"âŒ LLM Connection test error: {e}")

def test_ui_elements():
    """Test if UI elements are present"""
    print("\nğŸ§ª Testing UI Elements...")
    
    try:
        response = requests.get(f"{BASE_URL}/")
        if response.status_code == 200:
            html_content = response.text
            
            # Check for LLM configuration elements
            checks = [
                ("LLM Configuration", "LLM Configuration" in html_content),
                ("llmProvider", "id=\"llmProvider\"" in html_content),
                ("llmApiKey", "id=\"llmApiKey\"" in html_content),
                ("llmModel", "id=\"llmModel\"" in html_content),
                ("Test Connection", "Test Connection" in html_content),
                ("Save Config", "Save Config" in html_content),
                ("LLM Extraction", "LLM Extraction" in html_content),
                ("Auto (LLM + Fallback)", "Auto (LLM + Fallback)" in html_content)
            ]
            
            print("âœ… UI Elements check:")
            for name, found in checks:
                status = "âœ…" if found else "âŒ"
                print(f"   {status} {name}")
        else:
            print(f"âŒ UI request failed: {response.status_code}")
    except Exception as e:
        print(f"âŒ UI test error: {e}")

def main():
    """Run all LLM UI tests"""
    print("ğŸš€ Starting LLM UI Configuration Testing...")
    print(f"   Testing against: {BASE_URL}")
    
    # Test if server is running
    try:
        response = requests.get(f"{BASE_URL}/")
        if response.status_code != 200:
            print(f"âŒ Server not responding at {BASE_URL}")
            return
    except Exception as e:
        print(f"âŒ Cannot connect to server at {BASE_URL}: {e}")
        print("   Make sure the server is running with: python app.py")
        return
    
    print("âœ… Server is running")
    
    # Run tests
    test_llm_status()
    test_llm_config_save()
    test_llm_connection()
    test_ui_elements()
    
    print("\nğŸ‰ LLM UI configuration testing completed!")
    print("\nğŸ“ LLM Configuration Features:")
    print("   âœ… LLM enabled by default")
    print("   âœ… LLM Extraction and Auto options available")
    print("   âœ… Provider selection (OpenAI, Anthropic, Local)")
    print("   âœ… API Key input field")
    print("   âœ… Model configuration")
    print("   âœ… Base URL for local models")
    print("   âœ… Test Connection button")
    print("   âœ… Save Configuration button")

if __name__ == "__main__":
    main()
