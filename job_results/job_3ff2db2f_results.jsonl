{"job_id": "3ff2db2f", "status": "Completed", "total_files": 3, "successful_files": 3, "failed_files": 0, "skipped_files": 0, "skipped_reasons": {"unknown_format": 0, "file_size_limit": 0, "page_limit": 0}, "corrupt_files": 0, "start_time": "2025-09-16T21:04:57.630421", "end_time": "2025-09-16T21:05:09.193437", "processing_time_seconds": 11.563016, "metadata_options": ["author", "published_date", "abstract", "title", "topic"]}
{"filename": "Zero Trust Architecture.pdf", "success": true, "timestamp": "2025-09-16T21:05:03.738316", "metadata": {"title": "", "author": [{"first_name": "Wilbur", "last_name": "Ross", "full_name": "Wilbur Ross"}], "abstract": "This publication has been developed by NIST in accordance with its statutory responsibilities under the Federal Information Security Modernization Act (FISMA) of 2014, 44 U.S.C. § 3551 et seq., Public Law (P.L.) 113-283. NIST is responsible for developing information security standards and guidelines, including minimum requirements for federal information systems, but such standards and guidelines shall not apply to national security systems without the express approval of appropriate federal officials exercising policy authority over such systems. This guideline is consistent with the requirements of the Office of Management and Budget (OMB) Circular A-130.Nothing in this publication should be taken to contradict the standards and guidelines made mandatory and binding on federal agencies by the Secretary of Commerce under statutory authority. Nor should these guidelines be interpreted as altering or superseding the existing authorities of the Secretary of Commerce, Director of the OMB, or any other federal official. This publication may be used by nongovernmental organizations on a voluntary basis and is not subject to copyright in the United States. Attribution would, however, be appreciated by NIST.", "published_date": "August 2020", "topic": "architecture, cybersecurity, enterprise, network security, zero trust", "text": "AudienceThis document is intended to describe zero trust for enterprise security architects. It is meant to aid understanding of zero trust for civilian unclassified systems and provide a road map to migrate and deploy zero trust security concepts to an enterprise environment. Agency cybersecurity managers, network administrators, and managers may also gain insight into zero trust and ZTA from this document. It is not intended to be a single deployment plan for ZTA as an enterprise will have uni...", "file_type": "PDF", "upload_date": "2025-09-16T21:05:03.736394", "job_id": "3ff2db2f", "parser": "GROBID", "file_size": 966908}, "error": null, "skip_reason": null}
{"filename": "Factual Predictions.pdf", "success": true, "timestamp": "2025-09-16T21:05:06.232432", "metadata": {"title": "How Context Affects Language Models' Factual Predictions", "author": [{"first_name": "Fabio", "last_name": "Petroni", "full_name": "Fabio Petroni"}, {"first_name": "Patrick", "last_name": "Lewis", "full_name": "Patrick Lewis"}, {"first_name": "Tim", "last_name": "Rocktäschel", "full_name": "Tim Rocktäschel"}, {"first_name": "Yuxiang", "last_name": "Wu", "full_name": "Yuxiang Wu"}, {"first_name": "Alexander", "last_name": "Miller", "full_name": "Alexander Miller"}, {"first_name": "Sebastian", "last_name": "Riedel", "full_name": "Sebastian Riedel"}], "abstract": "When pre-trained on large unsupervised textual corpora, language models are able to store and retrieve factual knowledge to some extent, making it possible to use them directly for zero-shot cloze-style question answering. However, storing factual knowledge in a fixed number of weights of a language model clearly has limitations. Previous approaches have successfully provided access to information outside the model weights using supervised architectures that combine an information retrieval system with a machine reading component. In this paper, we go a step further and integrate information from a retrieval system with a pre-trained language model in a purely unsupervised way. We report that augmenting pre-trained language models in this way dramatically improves performance and that the resulting system, despite being unsupervised, is competitive with a supervised machine reading baseline. Furthermore, processing query and context with different segment tokens allows BERT to utilize its Next Sentence Prediction pre-trained classifier to determine whether the context is relevant or not, substantially improving BERT's zeroshot cloze-style question-answering performance and making its predictions robust to noisy contexts.", "published_date": "10 May 2020", "topic": "", "text": "IntroductionPre-trained language models such as BERT [Devlin et al., 2019] and RoBERTa [Liu et al., 2019] enabled state-of-the-art in many downstream NLP tasks [Wang et al., 2018a, 2019, Wu et al., 2019]. These models are trained in an unsupervised way from large textual collection and recent work [Petroni et al., 2019, Jiang et al., 2019, Talmor et al., 2019, Devlin et al., 2019] has demonstrated that such language models can store factual knowledge to some extent. However, considering the mill...", "file_type": "PDF", "upload_date": "2025-09-16T21:05:06.231037", "job_id": "3ff2db2f", "parser": "GROBID", "file_size": 599811}, "error": null, "skip_reason": null}
{"filename": "THE IMPACT OF COVID-19.pdf", "success": true, "timestamp": "2025-09-16T21:05:09.192528", "metadata": {"title": "NBER WORKING PAPER SERIES THE IMPACT OF COVID-19 ON STUDENT EXPERIENCES AND EXPECTATIONS: EVIDENCE FROM A SURVEY", "author": [{"first_name": "Esteban", "last_name": "Aucejo", "full_name": "Esteban Aucejo"}, {"first_name": "Jacob", "last_name": "French", "full_name": "Jacob French"}, {"first_name": "Maria", "last_name": "Paola", "full_name": "Maria Paola"}, {"first_name": "Ugalde", "last_name": "Araya", "full_name": "Ugalde Araya"}, {"first_name": "Basit", "last_name": "Zafar", "full_name": "Basit Zafar"}], "abstract": "Noah Deitrick and Adam Streff provided excellent research assistance. All errors that remain are ours. The views expressed herein are those of the authors and do not necessarily reflect the views of the National Bureau of Economic Research. NBER working papers are circulated for discussion and comment purposes. They have not been peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies official NBER publications.", "published_date": "", "topic": "", "text": "IntroductionThe disruptive effects of the COVID-19 outbreak have impacted almost all sectors of our society. Higher education is no exception. Anecdotal evidence paints a bleak picture for both students and universities.According to the American Council on Education, enrollment is likely to drop by 15% in the fall of 2020, while at the same time many institutions may have to confront demands for large tuition cuts if classes remain virtual. 1 In a similar vein, students face an increasingly unce...", "file_type": "PDF", "upload_date": "2025-09-16T21:05:09.191317", "job_id": "3ff2db2f", "parser": "GROBID", "file_size": 932271}, "error": null, "skip_reason": null}
